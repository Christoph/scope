{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing sparse matrix:   (0, 2)\t0.57735026919\n",
      "  (0, 6)\t0.57735026919\n",
      "  (0, 1)\t0.57735026919\n",
      "  (1, 3)\t0.411377911334\n",
      "  (1, 4)\t0.644502992261\n",
      "  (1, 0)\t0.644502992261\n",
      "  (2, 3)\t0.62922751467\n",
      "  (2, 5)\t0.777221162079\n",
      "  (3, 3)\t0.62922751467\n",
      "  (3, 5)\t0.777221162079\n",
      "Printing dense matrix : [[ 0.          0.57735027  0.57735027  0.          0.          0.\n",
      "   0.57735027]\n",
      " [ 0.64450299  0.          0.          0.41137791  0.64450299  0.          0.        ]\n",
      " [ 0.          0.          0.          0.62922751  0.          0.77722116\n",
      "   0.        ]\n",
      " [ 0.          0.          0.          0.62922751  0.          0.77722116\n",
      "   0.        ]]\n",
      "Pretty printig of co_occurrences count: <zip object at 0x107ca2208>\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "import numpy as np\n",
    "\n",
    "samples = ['awesome unicorns are awesome','batman forever and ever','I love batman forever','I love batman forever']\n",
    "bigram_vectorizer = TfidfVectorizer(ngram_range=(2, 2),binary=True) \n",
    "co_occurrences = bigram_vectorizer.fit_transform(samples)\n",
    "print('Printing sparse matrix:', co_occurrences) \n",
    "print('Printing dense matrix :', co_occurrences.todense()) \n",
    "sum_occ = np.sum(co_occurrences.todense(),axis=0)\n",
    "#print('Sum of word-word occurrences:', sum_occ)\n",
    "print('Pretty printig of co_occurrences count:', zip(bigram_vectorizer.get_feature_names(),np.array(sum_occ)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['and ever',\n",
       " 'are awesome',\n",
       " 'awesome unicorns',\n",
       " 'batman forever',\n",
       " 'forever and',\n",
       " 'love batman',\n",
       " 'unicorns are']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_vectorizer.get_feature_names()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2876820724517808"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = bigram_vectorizer.idf_\n",
    "\n",
    "b[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.69314718,  1.69314718,  1.69314718,  1.28768207,  1.69314718,\n",
       "        1.69314718,  1.69314718])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-24-f011fbc5178e>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-24-f011fbc5178e>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    from scope.methods.\u001b[0m\n\u001b[0m                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from numpy import *\n",
    "import numpy\n",
    "\n",
    "def entropy(counts):\n",
    "    '''Compute entropy.'''\n",
    "    ps = counts/float(sum(counts))  # coerce to float and normalize\n",
    "    ps = ps[nonzero(ps)]            # toss out zeros\n",
    "    H = -sum(ps * numpy.log2(ps))   # compute entropy\n",
    "    \n",
    "    return H\n",
    "\n",
    "def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk, math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re, string, numpy, itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1. ,  1.5,  2. ,  2.5])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = np.array([])\n",
    "v = numpy.append(v,[2,3])\n",
    "v = numpy.append(v,[4,5])\n",
    "v/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = [-i[0,0]*numpy.log2(i[0,0]) for i in a[:,0] if i[0,0] != 0]\n",
    "sum(b)\n",
    "\n",
    "sum([0.3,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools \n",
    "\n",
    "def entropy(vec):\n",
    "    b = [-i*numpy.log2(i) for i in vec if i != 0]\n",
    "    return sum(b)\n",
    "            \n",
    "def theta(i,x,a,k):\n",
    "    #print(\"theta:\",(a[i,x] + k) % 2,k,x)\n",
    "    return (a[i,x] + k) % 2\n",
    "\n",
    "bigram_vectorizer = CountVectorizer(ngram_range=(2, 2),binary=True) \n",
    "co_occurrences = bigram_vectorizer.fit_transform(samples)   \n",
    "bigram_tfidf_vectorizer = TfidfVectorizer(ngram_range=(2, 2),binary=True) \n",
    "co_occurrences_tfidf = bigram_tfidf_vectorizer.fit_transform(samples) \n",
    "idf = bigram_tfidf_vectorizer.idf_\n",
    "\n",
    "def joint_prob(i,j,a, idf):\n",
    "    out = np.array([])\n",
    "    total = np.sum(idf)\n",
    "    for k,l in itertools.product(range(2),range(2)):\n",
    "        vec = [theta(i,x,a,k)*theta(j,x,a,l)*idf[x] for x in range(0,len(idf))]\n",
    "        out = numpy.append(out,sum(vec))\n",
    "    return out/total\n",
    "\n",
    "def single_prob(i,a, idf):\n",
    "    out = np.array([])\n",
    "    total = np.sum(idf)\n",
    "    print(total)\n",
    "    for k in range(2):\n",
    "        vec = [theta(i,x,a,k)*idf[x] for x in range(0,len(idf))]\n",
    "        #print(vec)\n",
    "        out = numpy.append(out,sum(vec))\n",
    "    return out/total\n",
    "\n",
    "def partition_function(idf,a):\n",
    "    pass\n",
    "\n",
    "def mutual_information(i,j,a,idf):\n",
    "    single_i = single_prob(i,a, idf)\n",
    "    single_j = single_prob(j,a, idf)\n",
    "    joint = joint_prob(i,j,a,idf)\n",
    "    print(single_i)\n",
    "    print(single_j)\n",
    "    print(joint)\n",
    "    return entropy(single_i) + entropy(single_j) - entropy(joint)\n",
    "               \n",
    "    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.3154228345\n",
      "12.3154228345\n",
      "[ 0.22199556  0.77800444]\n",
      "[ 0.22199556  0.77800444]\n",
      "[ 0.22199556  0.          0.          0.77800444]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.76379463094498323"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mutual_information(3,2,co_occurrences.todense(),idf)\n",
    "#single_i = single_prob(0,co_occurrences.todense(), idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 2)\t0.57735026919\n",
      "  (0, 6)\t0.57735026919\n",
      "  (0, 1)\t0.57735026919\n",
      "  (1, 3)\t0.473629601033\n",
      "  (1, 4)\t0.622766007833\n",
      "  (1, 0)\t0.622766007833\n",
      "  (2, 3)\t0.605348508106\n",
      "  (2, 5)\t0.795960541568\n"
     ]
    }
   ],
   "source": [
    "print(co_occurrences_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2%2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 1, 1, 0, 0, 0, 1],\n",
       "        [1, 0, 0, 1, 1, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 1, 0]], dtype=int64)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "co_occurrences_tfidf.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools \n",
    "\n",
    "def entropy(vec):\n",
    "    b = [-i*numpy.log2(i) for i in vec if i != 0]\n",
    "    return sum(b)\n",
    "            \n",
    "def theta(i,x,a,k):\n",
    "    #print(\"theta:\",(a[i,x] + k) % 2,k,x)\n",
    "    return (a[i,x] + k) % 2\n",
    "\n",
    "bigram_vectorizer = CountVectorizer(ngram_range=(2, 2)) \n",
    "co_occurrences = bigram_vectorizer.fit_transform(samples)   \n",
    "bigram_tfidf_vectorizer = TfidfVectorizer(ngram_range=(2, 2),binary=True) \n",
    "co_occurrences_tfidf = bigram_tfidf_vectorizer.fit_transform(samples) \n",
    "idf = bigram_tfidf_vectorizer.idf_\n",
    "\n",
    "def joint_prob(i,j,a, idf):\n",
    "    out = np.array([])\n",
    "    total = np.sum(idf)\n",
    "    for k,l in itertools.product(range(2),range(2)):\n",
    "        vec = [theta(i,x,a,k)*theta(j,x,a,l)*idf[x] for x in range(0,len(idf))]\n",
    "        out = numpy.append(out,sum(vec))\n",
    "    return out/total\n",
    "\n",
    "def single_prob(i,a, idf):\n",
    "    out = np.array([])\n",
    "    total = np.sum(idf)\n",
    "    print(total)\n",
    "    for k in range(2):\n",
    "        vec = [theta(i,x,a,k)*idf[x] for x in range(0,len(idf))]\n",
    "        #print(vec)\n",
    "        out = numpy.append(out,sum(vec))\n",
    "    return out/total\n",
    "\n",
    "def partition_function(idf,a):\n",
    "    pass\n",
    "\n",
    "def mutual_information(i,j,a,idf):\n",
    "    single_i = single_prob(i,a, idf)\n",
    "    single_j = single_prob(j,a, idf)\n",
    "    joint = joint_prob(i,j,a,idf)\n",
    "    print(single_i)\n",
    "    print(single_j)\n",
    "    print(joint)\n",
    "    return entropy(single_i) + entropy(single_j) - entropy(joint)\n",
    "               \n",
    "    \n",
    "    \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
